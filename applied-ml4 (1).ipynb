{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11601111,"sourceType":"datasetVersion","datasetId":7275771}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ‚úÖ Check your environment\nimport torch\nprint('Torch version:', torch.__version__)\nprint('CUDA available:', torch.cuda.is_available())\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport random\n\n# Source folders\nSOURCE_IMG_DIR = '/kaggle/input/stationary/train/images'\nSOURCE_LBL_DIR = '/kaggle/input/stationary/train/labels'\n\n# Destination base\nDEST_BASE = '/kaggle/working/dataset'\n\n# Create folder structure\nfor folder in ['images/train', 'images/valid', 'labels/train', 'labels/valid']:\n    os.makedirs(os.path.join(DEST_BASE, folder), exist_ok=True)\n\n# Get all image filenames\nimage_files = [f for f in os.listdir(SOURCE_IMG_DIR) if f.endswith('.jpg')]\nrandom.shuffle(image_files)\n\n# Split 80-20\nsplit_idx = int(0.8 * len(image_files))\ntrain_files = image_files[:split_idx]\nvalid_files = image_files[split_idx:]\n\ndef move_files(files, split):\n    for img_file in files:\n        label_file = img_file.replace('.jpg', '.txt')\n        \n        # Copy image\n        shutil.copy(os.path.join(SOURCE_IMG_DIR, img_file),\n                    os.path.join(DEST_BASE, f'images/{split}', img_file))\n        \n        # Copy label\n        shutil.copy(os.path.join(SOURCE_LBL_DIR, label_file),\n                    os.path.join(DEST_BASE, f'labels/{split}', label_file))\n\nmove_files(train_files, 'train')\nmove_files(valid_files, 'valid')\n\nprint(f\"‚úÖ Done! Train: {len(train_files)} | Valid: {len(valid_files)}\")\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"yaml_content = \"\"\"\ntrain: /kaggle/working/dataset/images/train\nval: /kaggle/working/dataset/images/valid\n\nnc: 4\nnames: ['sharpener', 'pencil', 'scale', 'eraser']\n\"\"\"\n\nwith open('/kaggle/working/dataset/data.yaml', 'w') as f:\n    f.write(yaml_content)\n\nprint(\"‚úÖ data.yaml created successfully!\")\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cat /kaggle/working/dataset/data.yaml\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install YOLOv5\n!git clone https://github.com/ultralytics/yolov5\n%cd yolov5\n!pip install -r requirements.txt\n\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Train using our new split\n!python train.py --img 640 --batch 16 --epochs 50 --data /kaggle/working/dataset/data.yaml --weights yolov5s.pt --name stationary-detector\n\n# Save model\n!cp runs/train/stationary-detector/weights/best.pt /kaggle/working/","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import streamlit as st\nimport torch\nfrom PIL import Image\nimport numpy as np\nimport cv2\n\n# üöÄ Load model\nmodel = torch.hub.load('ultralytics/yolov5', 'custom', path='/kaggle/working/best.pt', force_reload=True)\n\n# üè∑Ô∏è Prices for each item\nprices = {\n    'sharpener': 20,\n    'pencil': 10,\n    'scale': 30,\n    'eraser': 15\n}\n\nst.title('üñçÔ∏è Stationary Item Detector & Bill Calculator')\n\nuploaded_file = st.file_uploader(\"üì∏ Upload an image of stationery items\", type=[\"jpg\", \"jpeg\", \"png\"])\n\nif uploaded_file is not None:\n    image = Image.open(uploaded_file)\n    st.image(image, caption='Uploaded Image', use_column_width=True)\n\n    # üîç Inference\n    results = model(image)\n    labels, cords = results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]\n    img_np = np.array(image)\n\n    for *box, conf, cls in results.xyxy[0]:\n        x1, y1, x2, y2 = map(int, box)\n        label = model.names[int(cls)]\n        cv2.rectangle(img_np, (x1, y1), (x2, y2), (255, 0, 0), 2)\n        cv2.putText(img_np, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n\n    st.image(img_np, caption='Detected Items', use_column_width=True)\n\n    # üßæ Bill calculation\n    detected_items = [model.names[int(cls)] for cls in labels]\n    bill = 0\n    st.subheader('üßæ Itemized Bill:')\n    for item in set(detected_items):\n        qty = detected_items.count(item)\n        st.write(f\"{item.capitalize()} √ó {qty} = {prices[item]*qty} PKR\")\n        bill += prices[item] * qty\n\n    st.success(f\"üí∞ Total: {bill} PKR\")\n","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null}]}